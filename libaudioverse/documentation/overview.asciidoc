[[overview]]
== Overview

This section tries to get you started with Libaudioverse quickly.
<<technical,A high-level technical overview>> can be found further along in this manual, but this section is probably what you actually want when you're starting.
Reading in order is recommended.

Each subsection starts with some Python  code and follows it with an explanation.
The translation to the C API should be fairly straightforward.
In the cases where it is not, this manual will make an effort to tell you what you need to use.

Note that the following examples work with Python 3.
Changes for Python 2 are minimal.

=== Playing a Sine Wave

Output a sine wave for 5 seconds:

....
import libaudioverse
import time

libaudioverse.initialize()

#Create a simulation using the defaults.
simulation = libaudioverse.Simulation()

#A sine node synthesizes a sine wave:
sine = libaudioverse.SineNode(simulation)

#In order to output, we connect to the simulation.
sine.connect_simulation(output = 0)

#The simulation will play once it has been told to use a specific output device.
simulation.set_output_device(-1)

time.sleep(5.0)
libaudioverse.shutdown()
....

This program synthesizes a sine wave for 5 seconds using a sine node.
The default frequency for a sine node is 440 HZ.

The first and last lines are simple initialization, and every program needs them.
Failure to initialize Libaudioverse will lead to errors, as will attempting to access Libaudioverse objects after shutdown.
For exploration, it is generally safe not to call `shutdown`.
This is typical practice when calling `python -i` to test a script interactively, as is done in other sections of this overview.
Failure to call `shutdown` will crash rarely, but it is still very important to have it in production code as this can and will happen.

Nodes are referred to by their class names (`SineNode`), their C enumerations (`Lav_OBJTYPE_SINE_NODE`) or an English description derived from their name, depending on the context.
For the most part, nodes either synthesize, process, or analyze audio.
Almost all nodes have outputs, numbered starting at 0.
Each output carries 1 or more channels of audio.
In this case, we take the output of the sine node and connect it to the simulation.
Any output connected to the simulation is audible at the speakers.

When you connect outputs to destinations with different channel counts, Libaudioverse will automatically do the necessary conversions to make everything work.
There is a detailed description of this algorithm <<technical-connections,elsewhere in this manual>>, but for the most part you need only know that Libaudioverse  understands and automatically converts between mono, stereo, 4.0, 5.1, and 7.1 without input on your part.

When requesting output devices, the default audio device is always -1.
In addition, Libaudioverse will attempt to change audio devices if the  default changes.
Specific audio devices are numbered starting at 0.

=== Properties on oscillators

This program sweeps a sine wave from 0 HZ to 10000 HZ while making it quieter.

....
import libaudioverse
import time

libaudioverse.initialize()
s=libaudioverse.Simulation()
n = libaudioverse.SineNode(s)
n.frequency = 0
n.connect_simulation(0)
s.set_output_device(-1)

#Recall that Python omits the last value.
for i in range(0, 1010, 10):
    n.mul.value = i/1000.0
    n.frequency.value = i
    time.sleep(0.02)
....

This example has audible artifacts.
The reasoning for this and how to fix it will be explained in a later section.

In addition to inputs, all nodes have properties.
Every node has at least `mul` and `add`.
`Mul` represents volume and ranges from -INFINITY to INFINITY.
If you set `mul` to a negative value, the node's output will be negated.
`Add`, not shown here, is the second of 3 standard properties, and adds a specific amount of DC offset.

Oscillators such as the sine node also have a number of other properties.
Every oscillator has `frequency`, `phase`, and `frequency_multiplier`.
`Frequency` is always in hertz, and `phase` is on the range 0 to 1.
`Frequency_multiplier` is an additional multiplier applied to the frequency of the oscillator, and is useful when building instruments; moving up and down by an octave on the musical scale is a doubling or halving of the frequency.

=== Buffers and Playing Files

The following loops a file until enter is pressed.

....
import libaudioverse

libaudioverse.initialize()

simulation = libaudioverse.Simulation()

print("Enter a path to a sound file.")
path = input()

buffer=libaudioverse.Buffer(simulation)
buffer.load_from_file(path)
buffer_player=libaudioverse.BufferNode(simulation)
buffer_player.buffer = buffer
buffer_player.looping = True
buffer_player.connect_simulation(0)

simulation.set_output_device(-1)

print("Press enter to exit.")
input()
libaudioverse.shutdown()
....

A buffer represents a chunk of decoded, resampled audio.
They can be loaded from a number of sources, but by far the most common is from a file.

Buffer nodes play the specified buffer, and have four properties of interest: `position`, `looping`, `rate`, and `end_count`.
`Position` is the current position of the buffer in seconds, `looping` controls if we loop, and `end_count` counts the number of times it has reached the end.
`End_count` exists so that you can play buffers synchronously or otherwise tell when they have ended without the coding complexity of using callbacks,  described later.
Note that callbacks will be more efficient for this purpose, as `end_count` requires spin waiting.
`Rate` controls the playback rate of the buffer.  1.0 is normal speed, 2.0 is twice as fast, etc.

As mentioned above, buffers store uncompressed, decoded audio data as float32, resampled to match the sampling rate of their simulation.
This means they are quite large.
Caching buffers is therefore very highly recommended, as 1 second of mono audio will take 176KB and a minute of stereo audio will take about 21 MB.
You cannot share buffers between simulations, but you can easily share them between buffer nodes.

=== Panning

This sets up a panner that you can play with in the Python REPL.  Use `python -i test.py` or similar to run it.

....
import libaudioverse
import time

libaudioverse.initialize()
s=libaudioverse.Simulation()

buffer_player  = libaudioverse.BufferNode(s)
buffer = libaudioverse.Buffer(s)
buffer.load_from_file("sound.wav")
buffer_player.buffer = buffer
buffer_player.looping = True

panner=libaudioverse.MultipannerNode(s, "default")
buffer_player.connect(output = 0, node = panner, input = 0)
panner.connect_simulation(0)
s.set_output_device(-1)
....

Multipanners are the most commonly used panner, as they support switching between HRTf, stereo, 4.0, 5.1, and 7.1 at runtime and without recreating objects.

The second parameter to the multipanner constructor is the path to an HRTF file.
As a special case, Libaudioverse recognizes the string "default" in all contexts in which an HRTF path is required.
This is an instruction to use the  dataset embedded in the Libaudioverse assemlby, and will be what most applications want.

The multipanner is an example of a node with an input.
Inputs are also numbered starting at 0, and accept a specific number of audio channels.
In this case, the multipanner has only one mono input.
If the channel count of the outputs connected to the input is different, Libaudioverse will perform its in-built conversion algorithms.
Multiple outputs may be connected to the same input.
In this case, the input will add all of the outputs, suitably converted to match the input's channel count.

The three properties of interest on a multipanner are `azimuth`, `elevation`, and `strategy`.
All panners have the first two, but `strategy` is unique to the multipanner.

`Azimuth` is an angle in degrees, such that 0 is straight in front, 90 is straight to the right, 180 is behind, and 270 is to the left.
Angles greater than 359 will wrap and negative values are allowed.

`Elevation` is an elevation from the horizontal plane, ranging from -90 to 90.
Unlike `azimuth`, elevation does not wrap, and is  only audible when using the HRTf strategy.

Finally, `strategy` controls the panning strategy to use.
You may see the allowed values by inspecting the <<enum-Lav_PANNING_STRATEGIES,Lav_PANNING_STRATEGIES>> enumeration, bound in Python as `libaudioverse.PanningStrategies.hrtf`, `libaudioverse.PanningStrategies.stereo`, etc.

=== Higher-level 3D components

This example sets up a source and an environment with HRTF enabled.
As with the above example, copy it to a file and run with `python -i`.

....
import libaudioverse
libaudioverse.initialize()

s=libaudioverse.Simulation()
n=libaudioverse.BufferNode(s)
b=libaudioverse.Buffer(s)
b.load_from_file("sound.wav")
n.buffer = b

e = libaudioverse.EnvironmentNode(s, "default")
e.default_panning_strategy = libaudioverse.PanningStrategies.hrtf
e.output_channels = 2
e.connect_simulation(0)

o=libaudioverse.SourceNode(s, e)
n.connect(0, o, 0)

s.set_output_device(-1)
....

The 3D components of Libaudioverse primarily involve two objects: an environment and a source node.

Environments represent the listener, provide defaults for new sources, aggregate source output, and allow for the creation of effect sends (see the next section).

Sources act as simple speakers.
A source takes the environment from which it is to be created as the second parameter to its constructor.
All audio sent through sources is panned, aggregated, and sent through output 0 of the source's environment.

It is important to note that unlike other nodes, sources are always connected to the environment with which they were created.
Also unlike other nodes, this connection is implicit and weak.
In the usual case, keeping a node alive will recursively keep all nodes connected to its inputs alive as well.
Sources break this rule.
As a consequence, you need to be sure to keep sources alive for as long as they are needed.
If you do not hold a strong reference to them, they will be garbage collected.
This is usually what you want.
You can find more information on object lifetimes in the <<technical,technical overview>>.

Environments and sources are the only nodes to make use of `float3` and `float6` properties, vectors of 3 and 6 floats respectively.
In Python, these are represented as 3-tuples and 6-tuples; changing only one component at a time is not allowed because vector updates need to always be atomic.

An environment has two properties of note, `position` and `orientation`.

`Position` is the position of the listener, and `orientation` the listener's orientation.
`Position` is represented as a float3, that is a vector of x, y, and z.
Without changing the orientation, the default coordinate system is as follows: positive x is right, positive y is up, and negative z is forward.
This was chosen to match OpenGL and OpenAL.

Orientation is represented as a `float6`.
The first three values of this are the at vector, a unit vector pointing in the direction that the listener is facing.
The second three are the up vector, a unit vector  pointing in the direction of the top of the listener.
These vectors must always be perpendicular.
If they are not, undefined behavior results.

There are two useful values for the `orientation` property.

The first, `(0, 1, 0, 0, 0, 1)` orients the coordinate system such that positive x is right, positive y is forward, and positive z is up.
This is useful for side-scrollers or other applications that do not involve turning.

The second is provided as a reference for those who do not know trigonometry, you can import math and use `(math.sin(theta), math.cos(theta), 0, 0, 0, 1)` to represent orientations as radians clockwise from north.
If you need to use degrees, note that `theta = degrees*math.pi/180.0`.

There are two immediately interesting properties on sources.
The first is `position`, the same as the environment's position but for sources.
The coordinate system of a source depends greatly on how you calculate the orientation of the listener, but using either or both of the above-suggested values will allow you to make east positive x and north positive y.
The other is `occlusion`, a value from 0 to 1.
This property controls an occlusion model, such that 0 is unoccluded and 1 is fully occluded.
Libaudioverse is unfortunately incapable of calculating occlusion for you, as this depends greatly on how you represent your level maps.
If you periodically update the `occlusion` property on all sources, however, Libaudioverse is more than happy to synthesize it.

There are many other properties on sources controlling the distance model and panning technique, but this section is quite long enough as-is.
You will want to be sure to read <<node-Lav_OBJTYPE_ENVIRONMENT_NODE,the Environment Node documentation>> and <<node-Lav_OBJTYPE_SOURCE_NODE,the Source Node documentation>>.

Finally, we must discuss `output_channels` and `default_panning_strategy`.
For technical reasons beyond the control of Libaudioverse, it is not possible to properly detect the type of audio device the user is using.
For this reason, the environment defaults to normal, stereo panning.
This is safe on basically every setup imaginable.

Every source has a `panning_strategy` property which can be used to change it for that source.
The purpose of `default_panning_strategy` on the environment is to specify what the `panning_strategy` value needs to be for new sources.
Setting it before creating any sources allows you to quickly and conveniently enable HRTF or surround sound support.

Unfortunately, it is possible for sources to have different panning strategies.
This is somewhat intensional, as you might choose to use stereo on less-important sources and HRTF on more-important ones in order to save CPU processing power.

But it leads to a difficult-to-resolve ambiguity.
If you set some of your sources to panning strategies with different channel counts, the environment is then unable to determine how many output channels it needs to have.
You might have meant the one with the lower channel count, but you might also have meant the one with the higher channel count.

In order to make it explicit and deterministic, environments require you to also specify the `output_channels` property.
Use 2 for stereo and HRTF, 4 for quad, 6 for 5.1, and 8 for 7.1.

=== Using Reverb

This snippet begins where the last example ended, and adds an environmental reverb.
As with the proceeding examples, run it with `python -i`.

....
reverb = libaudioverse.FdnReverbNode(s)
send = e.add_effect_send(channels = 4, is_reverb = True, connect_by_default = True)
e.connect(send, reverb, 0)
reverb.connect_simulation(0)
....

This example sets up an effect send, an additional output on the environment which is intended to be routed through effects.
Sources also pan a copy of their audio through the effect sends, using any strategy but HRTF as determined by the channel count.
Since we exclude HRTF, there is no ambiguity and a separate parameter would be redundant.

In this example we specify that all sources created and any created in future should be connected to the effect send, that it is for reverb, and that it has 4 channels.
Any attempt to create an effect send for reverb without using 4 channels will error.
Unlike non-reverb sends, effect sends for reverb pan their audio differently, such that the reverb fades in with distance.

`create_effect_send` returns the index of the newly created output, which we then feed through an FDN reverb and then to the simulation.
FDN reverbs are very simple reverberators.
The two most important properties are `density` and `t60`.
`Density` ranges from 0 to 1, specifying how close together the reflections are.
`T60` is the time it will take for the reverb to decay by 60 decibals, assuming that you play and then stop some input.
You can think of `t60` as roughly analogous to the reverb's duration.

FDN reverbs also contain configurable lowpass filters, and the ability to modulate the delay lines.
See the <<node-Lav_OBJTYPE_FDN_REVERB_NODE,documentation>> for more.

You have as many effect sends as you want, limited only by computation capacity.
Sources have functions to connect and disconnect themselves from effect sends in a fully configurable manner, and you can feel free to make your own custom effects, as well as the ones demonstrated here.

=== Using Automators

This sets up a siren-like effect and then turns off the sine node.

....
import time
import libaudioverse
libaudioverse.initialize()

s=libaudioverse.Simulation()
n=libaudioverse.SineNode(s)

n.frequency = 300
n.frequency.linear_ramp_to_value(1.0, 600)
n.frequency.linear_ramp_to_value(2.0, 300)
n.frequency.linear_ramp_to_value(3.0, 600)
n.frequency.linear_ramp_to_value(4.0, 300)
n.frequency.linear_ramp_to_value(5.0, 600)

n.mul.set(5.1, 1.0)
n.mul.linear_ramp_to_value(5.2, 0.0)

n.connect_simulation(0)
s.set_output_device(-1)
time.sleep(8.0)

libaudioverse.shutdown()
....

The above example demonstrates automators.
Libaudioverse processes audio in blocks, submitting each block to the sound card before beginning the next.
During the processing of a block, no API call can have effect.
The problem with this setup is that there is no way to allow user code to be called more rapidly than once per block.
Worse yet, being called exactly once per block requires extra work and degrades performance.
Automators exist to allow smoothe property modifications despite this downside.

The linear ramp is an automator which begins moving the value of the property to the specified value.
The first argument is the time at which the property must reach the target value erelative to the current time, and the second the value which must be reached.
Set is a similar function, but instead moves the value instantaneously at the specified time.
Note that all times are specified relative to now, and that it is not possible to schedule automators in the past.

What we do in the above example, therefore, is schedule a triangular sweep of the frequency between 300 HZ and 600 HZ.
Then we schedule a fade-out using the set and linear ramp.

There are three notable points about automators worth specifically pointing out, though the first may or may not be obvious.

First, the linear ramp and many other automators use the "previous" value of the property.
To that end, it is necessary to set the property to the starting point before automating it.
If you don't, then it will start from wherever it was last set; this may or not be a problem, depending on application structure.

Second, setting a property cancels all pending automators.
This is to avoid strange conditions and make validation of inputs possible.

Finally, the setup with mul is a bit strange.
Since linear ramps start immediately, it is often necessary to schedule another automator before them.
Since we don't want mul to start ramping until a bit after 5 seconds, we use the set automator.
This makes the linear ramp's previous value the endpoint of the set automator, such that it only takes effect afterwords.
If that line is commented out, the sine node will get progressively quieter for the entire example rather than rapidly fading out at the end.

Properties come in two variations, a-rate and k-rate.
Most properties are k-rate properties, and their value is computed once per block.
Some are processed as much as every sample, such as the sine node's frequency and the mul propperty on all nodes.
These are referred to as the a-rate properties.

The biggest advantage of automators is that they are computed per-sample on a-rate properties.
Since both `mul` and `frequency` are a-rate, the above example will not become choppy, even should the block size be set absurdly high.

=== Connecting Nodes to Properties

This example sets up ring modulation.
As with other examples, you will want to run it interactively; this one is worth experimenting with.

....
import libaudioverse
libaudioverse.initialize()

s = libaudioverse.Simulation()
n1, n2 = libaudioverse.SineNode(s), libaudioverse.SineNode(s)

n2.mul = 0.0

n1.frequency = 100
n2.frequency=400

n1.connect_property(0, n2.mul)
n2.connect_simulation(0)
s.set_output_device(-1)
....

The above example shows how to connect  the output of a node to a property.
This works only with float and double properties.
Attempting to do it to any other property type will cause an error.

As with automators, this type of control can be sample-perfect on a-rate properties.
Unlike automators, connected nodes act as offsets to whatever the property would be without the node.
It is common, therefore, to first set the target property to 0.

You can connect multiple outputs to the property.
They function identically to 1-channel inputs, including downmixing logic.

While Libaudioverse already has a ringmod node which is admittedly much more efficient, this is the simplest example to demonstrate it with.
A similar technique can be used to set up FM synthesis or continuous filter sweeping, as well as a wide variety of other interesting effects.
