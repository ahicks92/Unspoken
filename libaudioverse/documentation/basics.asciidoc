[[basics]]
== Basic Concepts of Libaudioverse

In order to begin using Libaudioverse's 3d components, it is not necessary to fully understand this section.
For a gentler and much more hands-on introduction, see the tutorials.

[[basics-simulation]]
=== The Simulation

The simulation is the main entry point to Libaudioverse.
When created, the simulation fixes the sampling rate and block size of all nodes that use it.

For efficiency, Libaudioverse audio is processed in blocks.
At the beginning of each block, properties are read and updated, node connections examined,  and audio synthesized.
The most useful way to think of the block size is the number of samples for which any node connections and property settings are fixed.

More concretely, when the simulation has an associated output device, the block size is the number of frames of audio that will be submitted to the sound card at once.
Otherwise, it is the number of frames of audio returned by a call to `Lav_getBlock`.

See <<basics-audio-output,the section on outputting audio>> for information about associating the simulation to an audio output device.

If an app is changing multiple properties, it is possible for Libaudioverse to decide to mix a block before they are all at their new values.
To prevent this, the simulation may be treated like a lock.
While locked, all other threads (including the internal mixer thread) will be unable to access this simulation or its objects.
In the C API, this is available through `Lav_simulationLock` and `Lav_simulationUnlock`.

IMPORTANT: Locking the simulation is not called something else for a reason.
If you fail to apply all the considerations you would apply to regular locks, deadlock will result.
Note that all objects lock their simulations when accessed.
If your app uses multiple simulations and also locks more than one of them at any point, then be careful not to access objects from the other simulation.

If the requirement for syncing with audio perfectly exists, the block callback may be used.
If set, it will be called every block, receiving the simulation and the simulation's current time as parameters.
Code in this function can be thought of as executing between a `Lav_simulationLock` and `Lav_simulationUnlock` pair, and all the same considerations apply.
This is by far the most complicated way to drive Libaudioverse, but is helpful when implementing event timelines or virtual instruments.

[[basics-buffers]]
=== Buffers

Buffers are the simplest Libaudioverse object: they hold audio data.
This data can come from anywhere and be at any sampling rate.
When the buffer's data is set, the data in it is resampled to match the sampling rate of the simulation used to create it.

Buffers are intended to allow many copies of the same data to be in use simultaneously.
Instead of loading multiple copies of a file or other data,
it is possible to use the same buffer handle in multiple places.
In addition, the expensive resampling operation need only occur once.

Due to the resampling, buffers are not ideal for streaming; if you need streaming, use a streaming file node, pull node or push node.

[[basics-nodes]]
=== Nodes

Nodes can be thought of as black boxes that manipulate audio.
The following lists some things that nodes can do, roughly in the order that you will need them.

- Produce audio, for example the buffer node and the sine node.
- Modify audio, for example the biquad and IIR filter sections.
- perform analysis or otherwise allow observation of audio as it passes through Libaudioverse.
- Execute side effects like recording to files.

If there is not a node that does what you want, it is even possible to make your own.

If the simulation is the entry point of Libaudioverse, the node is the actual functionality.
Since it is difficult to separate nodes from other concepts, most of the explanation of their features is in other subsections.
Every node will run at most once per block, as described <<basics-audio-processing,here>>.
Inputs and outputs are discussed <<basics-connections,here>>.
The specifics of properties are also discussed in a dedicated section, <<basics-properties,namely this one>>.

While properties are discussed later, one deserves special mention here. Every node has a state, either playing, always playing, or paused.  The specific meanings of these are discussed below alongside the audio algorithm, but references to a node's state refer to this property.

[[basics-properties]]
=== Properties

Every node can have any number of properties.
To find out specifically which properties a specific node of interest has, see the node reference.

There are two broad categories of properties: k-rate and a-rate.
These terms are borrowed from other systems similar to Libaudioverse.
A k-rate property is evaluated at the beginning of a block and not read again until the next block;
an a-rate property is read every sample.
Only float and double properties can be a-rate.

The following types of properties are present in Libaudioverse:

- Boolean: Holds 0 or 1.
In the C API, this is manipulated using the functions for int properties.
The distinction is only important in language bindings, which map boolean to the language's native boolean type.
- Int: holds a 32-bit integer.
- Float: Holds a 32-bit floating point value.
- Double: Holds a64-bit double.
- Buffer: Holds a reference to a buffer.
- Float3: Holds a vector of 3 floats, primarily for position in the 3D audio components of this library.
All 3 components must be updated at once.
- Float6: Holds a vector of 6 floats, also for use primarily by the 3D components.
All 6 components must be updated at once.
- Int array: Holds an array of integers with limits on its length.
- Float array: Holds an array of floats with limits on its length.
- String: A string.

Float and double properties need further discussion.
A float or double property, hereafter an automatable property, has a couple extra features.

The first of these is that it is possible to connect nodes to automatable properties, in much the same way that one connects nodes to other nodes.
When this happens, the audio of all connected nodes is downmixed to mono, added, and used as an offset on the property's set value.

Automatable properties also support automators, a concept borrowed directly from Web Audio.
An automator moves the value of a property according to a specific instruction.  The current automators are as follows:

- Linear ramp to value: moves the property to a specific value by a specific time.
- Envelope: Execute linearly interpolated envelopes from arrays of samples.

Automators are scheduled relative to the local time of a node and have two important properties.
The start time of an automator, sometimes just called the time, is the time at which it is scheduled.
For most automators, the property's value will be affected starting at the end of the last automator, and proceeding to the time at which the automator in question is scheduled.
A very few automators have the second property, namely a duration.
It is an error to schedule another automator so that it is running at the same time as an already scheduled automator.
This is only an issue for those automators with documented durations or if your code tries to stack automators at exactly the same point on Libaudioverse's internal timeline.

In the various programming language bindings, automation methods are found on the classes which represent the properties themselves.
For example, in Python, `mysine.frequency.linear_ramp_to_value(1.0, 500.0)` will move the frequency of the sine node from where it is now to 500.0 HZ over 5 seconds.

Changing the value of an automatable property will cancel all automators while leaving nodes connected.
If you wish to disconnect nodes, you must do so manually.

To be more formal, the value of an automatable property for time `t` where `t` is relative to the node's current time is computed as follows:

- If the property is a k-rate property, adjust `t` to the beginning of the block.
- Let the intrinsic value be the value of the property or, if the property has automators scheduled, the value of those automators at `t`.
- let the node value be the value of all connected nodes at `t`, summed.
- The value of the property is the sum of the intrinsic and node values.

[[basics-connections]]
=== Connections

Every node has some number of inputs and outputs.
In order to feed the output of nodes to other nodes, it must be possible to form connections between them.

Libaudioverse takes the approach of specifying connections  as destinations for outputs.
That is, given some node `n`, output `o`, destination node `n2`, and input index `i`:


....
Lav_nodeConnect(n, o, n2, i);
....

Forms a connection from output `o` of node `n` to input `i` of node `n2`.

Any output may be connected to any number of inputs.
Any input may have any number of outputs connected to it.
Libaudioverse has no simple mixer node.
To build one, just connect all the outputs to be mixed to the same input of a gain node.
Since all incoming outputs for a specified input are added already, making your own simple mixer is usually not advantageous.

You can use `Lav_nodeConnectProperty` to connect an output to a property, and 
`Lav_nodeConnectSimulation` connects an output to the node's simulation.

It is not possible to introspect the graph of connected nodes.
It is also not possible to disconnect specific output-input pairs.
The only way to break connections is with `Lav_nodeDisconnect`, which breaks all connections involving a specified output.

In most language bindings, nodes are kept alive as long as they have an output which is connected to something that is also alive.
Note that this is not a feature of the C API.

Making connections can error in two cases.
The first of these is when the requested operation would cause a cycle.
If Libaudioverse allowed such connections, then it would be possible for applications to cause infinite loops.

The second case in which forming connections can error is an attempt to connect to something made using a different simulation.
It is only possible to form connections between objects of the same simulation.
 
[[basics-channels]]
=== Channels and Automatic Conversion

Every input and output has a channel count associated with it.
If both the input and the output in questionh have one of the values in the following table, Libaudioverse will convert the audio as appropriate.

|====
| Number | Name | Order
| 1 | Mono | mono
| 2 | Stereo | Front Left, Front Right
| 6 | 5.1 SurroundSound | Front Left, Front Right, Center, LFE, Back Left, Back Right
| 8 | 7.1 Surround Sound | Front left, Front Right, Center, LFE, Back Left, Back Right, Side Left, Side Right
|====

It is not currently possible to query the channel count of an output or an input.
All automatable properties are treated as mono.
The simulation's input can change from block to block, as its channel count depends on a parameter to `Lav_simulationGetBlock`.
All other inputs and outputs depend only on parameters provided by your app or, in some cases, the values of specific properties.

In the case where one end of the connection is not using one of the standard channel counts, one of two things happens.
If the input has less channels than the output, additional channels are filled with zeros.
If the output has less channels than the  input, additional channels are dropped.

If you need to manipulate channels individually, the channel splitter and channel merger nodes allow doing so.
This is one of the three cases wherein the channel order matters:
a channel splitter splits an output into n outputs, where n is a number you specify to its constructor.
The first output is the first channel, the second the second, etc.

The other two cases in which the channel orders can be observed directly are callback functions that manipulate audio and `Lav_simulationGetBlock`.
These cases are discussed in other sections.

[[basics-audio-processing]]
=== Audio Processing and Extracting Audio

Every node has three states: stopped, playing, and always playing.
The following is pseudocode for the processing algorithm.

....
function process(node):
  if node.has_processed is True then return
  if node.state=="stopped" then return
  for i in get_dependents(node):
    process(i)

function get_block(simulation):
  for i in simulation.input_connection.nodes:
    process(i)
  for i in simulation.nodes:
    if i.state=="always playing" and not i.has_processed:
      process(i)
  block = sum(simulation.input_connection.connected_outputs)
....

This looks complicated.
The tutorials make a point of showing how to use it to your advantage.
Note that, if we always process all nodes, it is not possible to meaningfully use the factory pattern, as Libaudioverse might advance by a block while we are building and configuring objects.

There are two ways in which this algorithm may be triggered.

The rarest is with `Lav_simulationGetBlock`, taking as parameters a channel count, a buffer, and a flag to either allow automatic mixing to be applied or to force extra channels to be dropped.
If your application wishes to write audio to a file or implement a VST plugin, this is the function it is using.
The most common method, however, is when the simulation is associated with an output device.

[[basics-devices]]
=== Audio Devices

Libaudioverse represents audio devices with an index from -1 to `n-1`, where `n-1` is the maximum number of devices on  the system.
0 through `n-1` are specific output devices.
To get specific information, use the device enumeration API.

-1 is special.
-1 is always available and represents the default audio device.
In addition, if the default audio device changes, -1 will attempt to change the simulations' device with it.

Simulations are associated with output devices by `Lav_simulationSetOutputDevice` and can be made to stop playing with `Lav_simulationClearOutputDevice`.
It is safe to call `Lav_simulationSetOutputDevice` more than once, but this function will block until all queued blocks have played.

`Lav_simulationSetOutputDevice` takes a parameter called mixahead.
It is possible for the OS to preempt Libaudioverse or for Libaudioverse to be under a heavy workload.
Mixahead specifies a number of blocks of audio  that should be prepared ahead of time in order to provide some leeway.
To calculate the  approximate latency varius mixahead values introduce, use `block_size*mixahead/sr`.

Note that introducing a latency of 100 MS using a block size of 1024 works for most people.
This is about a  mixahead of 5.
Many systems can safely go much lower, however, so providing an option to do so may be advisable.
This is especially true of real-time apps such as games and synths, where 100 MS is a significant latency.
It is suggestred to fix the block size at a size where the audio updates are not noticeable, a value which highly depends on the application in question.
In most cases,  allowing configuration of the mixahead is more than enough.

The only "safe" default for channels on desktop platforms is stereo, which should be played reliably by virtually any setup anywhere.
Other channel counts may or may not work as expected.

It is an unfortunate consequence of the complexity of the modern audio stack that the desired default cannot be determined automatically.
Libaudioverse attempts to query this information for you, but modern OSes will happily lie.
As an example, Windows WaveOut is more than happy to claim support for 7.1 surround sound on stereo headphones.

Furthermore, Some hardware such as the Logitech G930 attempts to provide surround sound imulation.
Such hardware  may claim to be a 5.1 or 7.1 surround sound device, even when it is configured to be stereo headphones.

Applications for which stereo is not good enough should default to stereo anyway.
Libaudioverse provides the ability to reconfigure the channel account at runtime via the multipanner and properties on the 3D simulation components.

[[basics-events-callbacks]]
=== Events and Callbacks

An event is a function that is called in order to inform your application of something.
Libaudioverse does not expect anything from the application when an event is fired, and it is safe to call the Libaudioverse API from events.
Events make no guarantee on their latency, and are far from sample accurate.
Examples of events include indication that a file has ended.
Events are manipulated from a node-neutral API and always have the same signature.
It is not possible for Libaudioverse to send info with an event, save for the node that caused it and the fact that it has happened.
Blocking inside events may cause further events not to fire in a timely manner, but will not otherwise adversely effect audio.

Callbacks represent requests  or special-case notifications.
Callbacks mandate that you not touch any of the Libaudioverse API for any purpose, and run inside the mixing threads of Libaudioverse.
Blocking inside a callback should be avoided if possible, as doing so will slow down audio mixing.
Examples of callbacks include passing audio data out to your application (the graph listener) or requesting audio data from the application to be fed to further nodes in the pipeline (the pull node).
One notable use for callbacks is the implementation of a custom node.
Callbacks each have a different signature and are manipulated through dedicated setters on a node-specific basis.
Unlike events, the C API does not provide a way to query the currently set calllback.

It is not safe to assume that a callback or event will be called from a specific thread.
It is possible for them to change threads at runtime at any time and for any reason.
Exactly one guarantee is made: if you are not using `Lav_simulationGetBlock`, they will never happen on the main thread of your application.
This does imply that use of `Lav_simulationGetBlock` may cause them to run on the main thread, so be aware of it.

the specifics of each event and callback are documented in the node reference.
